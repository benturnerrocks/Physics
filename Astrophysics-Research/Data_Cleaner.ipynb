{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from PyAstronomy import pyasl\n",
    "import hpfspec2\n",
    "import glob\n",
    "import random\n",
    "import datetime\n",
    "import ipywidgets as widget\n",
    "import ipympl\n",
    "import os\n",
    "import pandas as pd\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAW DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3443\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#where do we pull NPY files and put files to plot #etalon data1 or data2 and also LFC\n",
    "\n",
    "#where we store the csv files basepath: /data4/HPF/etalon/data/DataToPlot/\n",
    "storageSpace = ['DataToPlot_Etalon','DataToPlot_LFC','DataToPlot_Etalon_c2_sQ','DataToPlot_LFC_c2_sQ']\n",
    "#where we pull the npy files basepath: /data3/HPF/etalon/data/Fitted_Data/\n",
    "pullDataFrom = ['Fitted_Data_Etalon','Fitted_Data_LFC','Fitted_Data_Etalon_c2_sQ','Fitted_Data_LFC_c2_sQ']\n",
    "\n",
    "#pull the NPY Files\n",
    "allNPYfiles = sorted(glob.glob('/data3/HPF/etalon/data/Fitted_Data/'+pullDataFrom[2]+'/*.npy'))\n",
    "print(len(allNPYfiles))\n",
    "print(len(storageSpace))\n",
    "print(len(pullDataFrom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell loads all the files \n",
    "#and gets the centroid, FWHM, and velocities of multiple mode per file\n",
    "\n",
    "for dataIndex in range(len(pullDataFrom)):  #we are pulling for each type of data\n",
    "    allNPYfiles = sorted(glob.glob('/data3/HPF/etalon/data/Fitted_Data/'+pullDataFrom[dataIndex]+'/*.npy')) #pull npy files\n",
    "    \n",
    "    #SETTINGS BEGIN\n",
    "    \n",
    "    allData = True #if we want to cut off the data ends\n",
    "    fileStart = 0\n",
    "    fileCutOff = 5000\n",
    "    storeInOther = True #use this if doing small test or data (ONLY HAVE TURNED OFF IF DOING THE LARGE SCALE CHANNELS)\n",
    "\n",
    "    lookForBAD = False #look for bad files\n",
    "\n",
    "    Slim_Analysis = False #if we want a quick analysis (NOT EVERY FILE)\n",
    "    slimness = 10 #larger means less data, this skips to every nth file\n",
    "\n",
    "    splitByPixel = False\n",
    "    pixelToStartAt = 1537\n",
    "    pixelToEndBy = 1792\n",
    "\n",
    "    #if we want to look at a certain number of orders or modes\n",
    "    num_of_orders = 1 \n",
    "    num_of_modes = 20 \n",
    "    all_orders = True #do we want all orders or modes\n",
    "    all_modes = True\n",
    "    start_order = 0 #if only looking at certain orders or modes, where do you wanna look around\n",
    "    start_mode = 60\n",
    "    \n",
    "    AVG_over_time = False #do we want to average the data from multiple nearby files to get rid of noise? #NOT IMPLEMENTED\n",
    "    files_to_AVG_over = 10 #if AVG_over_time\n",
    "\n",
    "    #what average method do we want\n",
    "    wantAVG = False\n",
    "    wantMED = False\n",
    "    wantBIWEIGHT = True\n",
    "    \n",
    "    #SETTINGS END\n",
    "    \n",
    "    #CODE BEGINS (DONT CHANGE ANYTHING BELOW)\n",
    "\n",
    "    #initialize data structures\n",
    "    centroidsWL = []\n",
    "    fwhmWL = []\n",
    "    centroidsPIX = []\n",
    "    fwhmPIX = []\n",
    "    v_list = []\n",
    "    times = []\n",
    "    if lookForBAD:\n",
    "        cur_bad_files = file1.read().splitlines() #pull the current bad files if looking for weird data #replace file1 with file that has bad file path names\n",
    "        bad_files = []\n",
    "\n",
    "\n",
    "    if not Slim_Analysis:\n",
    "        slimness = 1\n",
    "    if allData:\n",
    "        fileStart = 0\n",
    "        fileCutOff = len(allNPYfiles)\n",
    "\n",
    "    rangeToLook = range(fileStart,fileCutOff,slimness)\n",
    "\n",
    "    for i in rangeToLook: #going over every file\n",
    "        fitdata = np.load(allNPYfiles[i],allow_pickle=True)[()]\n",
    "        new_centroid_WL = []\n",
    "        new_fwhm_WL = []\n",
    "        new_centroid_PIX = []\n",
    "        new_fwhm_PIX = []\n",
    "        temp_v_list = []\n",
    "        speed_light = 2.99792458*10**8    \n",
    "\n",
    "        if i==fileStart: #pull the original spectrum to calculate v-shifts off of\n",
    "            original_spectrum = fitdata\n",
    "\n",
    "\n",
    "        if all_orders: #adding all orders to get the average over all the orders in a spectrum\n",
    "            num_of_orders = len(fitdata.keys())\n",
    "            start_order = 0\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(num_of_orders): #going over every order\n",
    "            if all_modes or splitByPixel: #adding all the modes of an order to get the average over that order\n",
    "                num_of_modes = len(fitdata[j+start_order].keys())\n",
    "                start_mode = 0\n",
    "                mode_count = 0\n",
    "\n",
    "            for k in range(num_of_modes): #going over every mode and pulling everything we need from that mode\n",
    "                \n",
    "                #isolate the current mode\n",
    "                curMode = fitdata[j+start_order][k+start_mode]\n",
    "                curPix = curMode['centroid_pix']\n",
    "                \n",
    "                #first test if we are too far\n",
    "                if (curPix>pixelToEndBy) and splitByPixel:\n",
    "                    break #if we have gone past our desired pixel, we want to stop\n",
    "                #pull all information\n",
    "                if ((curPix>=pixelToStartAt) and splitByPixel) or not splitByPixel:\n",
    "                    cur_centroid_WL = curMode['centroid_wl']\n",
    "                    cur_fwhm_WL = curMode['fwhm_wl']\n",
    "                    cur_centroid_PIX = curMode['centroid_pix']\n",
    "                    cur_fwhm_PIX = curMode['fwhm_pix']\n",
    "\n",
    "                    new_centroid_WL.append(cur_centroid_WL)\n",
    "                    new_fwhm_WL.append(cur_fwhm_WL)\n",
    "                    new_centroid_PIX.append(cur_centroid_PIX)\n",
    "                    new_fwhm_PIX.append(cur_fwhm_PIX)\n",
    "\n",
    "                    #calculate and save the velocity values\n",
    "                    orig_wl = (original_spectrum[j+start_order][k+start_mode]['centroid_wl'])*(10**(-10))\n",
    "                    cur_wl = (curMode['centroid_wl'])*(10**(-10))\n",
    "                    cur_v = speed_light*(cur_wl-orig_wl)/orig_wl \n",
    "                    temp_v_list.append(cur_v)\n",
    "\n",
    "                    #keep track of where we are looking to use for naming the file\n",
    "                    if mode_count==0:\n",
    "                        mode_location = k\n",
    "                    mode_count+=1\n",
    "\n",
    "                if lookForBAD: #pull any bad files\n",
    "                    #test the fwhm wl, if we need we can do it for centroids too, but fwhm is more useful\n",
    "                    if np.isnan(cur_fwhm_WL) or (int(cur_fwhm_WL) not in range(0,2)):\n",
    "                        if allNPYfiles[i] not in cur_bad_files and allfiles[i] not in bad_files:\n",
    "                            bad_files.append(allfiles[i])\n",
    "\n",
    "        centroidsWL.append(new_centroid_WL)\n",
    "        fwhmWL.append(new_fwhm_WL)\n",
    "        centroidsPIX.append(new_centroid_PIX)\n",
    "        fwhmPIX.append(new_fwhm_PIX)\n",
    "        v_list.append(temp_v_list)\n",
    "\n",
    "        if pullDataFrom[dataIndex] == 'Fitted_Data_LFC':\n",
    "            curTime = allNPYfiles[i][57:72]\n",
    "        elif pullDataFrom[dataIndex] == 'Fitted_Data_Etalon_c2_sQ':\n",
    "            curTime = allNPYfiles[i][66:81]\n",
    "        elif pullDataFrom[dataIndex] == 'Fitted_Data_LFC_c2_sQ':\n",
    "                curTime = allNPYfiles[i][63:78]\n",
    "        else:\n",
    "            curTime = allNPYfiles[i][60:75]\n",
    "        times.append(datetime.datetime.strptime(curTime,'%Y%m%dT%H%M%S'))\n",
    "\n",
    "\n",
    "    #AVERAGE\n",
    "    \n",
    "    average_array_centroid_wl = []\n",
    "    average_array_centroid_pix = []\n",
    "    average_array_fwhm_wl = []\n",
    "    average_array_fwhm_pix = []\n",
    "    average_array_v = []\n",
    "    \n",
    "    for eachArray in centroidsWL:\n",
    "        if wantAVG:\n",
    "            average_centroid = np.nanmean(eachArray)\n",
    "        elif wantMED:\n",
    "            average_centroid = np.nanmedian(eachArray)\n",
    "        else:\n",
    "            average_centroid = astropy.stats.biweight_location(eachArray,ignore_nan=True)\n",
    "\n",
    "        average_array_centroid_wl.append(average_centroid)\n",
    "\n",
    "    for eachArray in centroidsPIX:\n",
    "        if wantAVG:\n",
    "            average_centroid = np.nanmean(eachArray)\n",
    "        elif wantMED:\n",
    "            average_centroid = np.nanmedian(eachArray)\n",
    "        else:\n",
    "            average_centroid = astropy.stats.biweight_location(eachArray,ignore_nan=True)\n",
    "\n",
    "        average_array_centroid_pix.append(average_centroid)\n",
    "\n",
    "    for eachArray in fwhmWL:\n",
    "        if wantAVG:\n",
    "            average_fwhm = np.nanmean(eachArray)\n",
    "        elif wantMED:\n",
    "            average_fwhm = np.nanmedian(eachArray)\n",
    "        else:\n",
    "            average_fwhm = astropy.stats.biweight_location(eachArray,ignore_nan=True)\n",
    "\n",
    "        average_array_fwhm_wl.append(average_fwhm)\n",
    "\n",
    "    for eachArray in fwhmPIX:\n",
    "        if wantAVG:\n",
    "            average_fwhm = np.nanmean(eachArray)\n",
    "        elif wantMED:\n",
    "            average_fwhm = np.nanmedian(eachArray)\n",
    "        else:\n",
    "            average_fwhm = astropy.stats.biweight_location(eachArray,ignore_nan=True)\n",
    "\n",
    "        average_array_fwhm_pix.append(average_fwhm)\n",
    "\n",
    "    for eachArray in v_list:\n",
    "        if wantAVG:\n",
    "            average_v = np.nanmean(eachArray)\n",
    "        elif wantMED:\n",
    "            average_v = np.nanmedian(eachArray)\n",
    "        else:\n",
    "            average_v = astropy.stats.biweight_location(eachArray,ignore_nan=True)\n",
    "\n",
    "        average_array_v.append(average_v)\n",
    "\n",
    "    #SAVING THE DATA\n",
    "       \n",
    "    #naming structure\n",
    "    if wantMED:\n",
    "        AVG = 'Median '\n",
    "    elif wantBIWEIGHT:\n",
    "        AVG = 'Bi-Weight '\n",
    "    else:\n",
    "        AVG = 'Average '\n",
    "\n",
    "    if Slim_Analysis:\n",
    "        part1 = 'Slim'\n",
    "    else:\n",
    "        part1 = 'Full'\n",
    "    if all_orders:\n",
    "        part2 = 'All_Orders'\n",
    "    else:\n",
    "        part2 = str(num_of_orders)+'OrdersAt'+str(start_order)\n",
    "    if all_modes:\n",
    "        part3 = 'All_Modes'\n",
    "    else:\n",
    "        part3 = str(mode_count)+'ModesAt'+str(mode_location)\n",
    "\n",
    "    name = part1+'RawData_'+part2+'_'+part3\n",
    "\n",
    "\n",
    "    # intialise data of lists for RAW data.\n",
    "    data = {'Date':times,AVG+'Centroid (Å)':average_array_centroid_wl,AVG+'FWHM (Å)':average_array_fwhm_wl,AVG+'Centroid (pixels)':average_array_centroid_pix,AVG+'FWHM (pixels)':average_array_fwhm_pix,AVG+'Velocity Shifts (m/s)':average_array_v}\n",
    "\n",
    "    # Create DataFrame\n",
    "    df_out = pd.DataFrame(data)\n",
    "    \n",
    "    # data to csv\n",
    "    if storeInOther:\n",
    "        namingScheme = '/Other/'\n",
    "    else:\n",
    "        namingScheme = '/'\n",
    "    df_out.to_csv('/data4/HPF/etalon/data/DataToPlot/'+storageSpace[dataIndex]+namingScheme+name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bad_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9f602260b126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bad_files' is not defined"
     ]
    }
   ],
   "source": [
    "print(bad_files) #if it is pulling bad files, print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
